// ä¸Šä¼ ç®¡ç†å™¨
//
// è´Ÿè´£ç®¡ç†å¤šä¸ªä¸Šä¼ ä»»åŠ¡ï¼š
// - ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†
// - å¹¶å‘æ§åˆ¶ï¼ˆæ”¯æŒè°ƒåº¦å™¨æ¨¡å¼å’Œç‹¬ç«‹æ¨¡å¼ï¼‰
// - è¿›åº¦è·Ÿè¸ª
// - æš‚åœ/æ¢å¤/å–æ¶ˆ
//
//  æ”¯æŒå…¨å±€è°ƒåº¦å™¨æ¨¡å¼
// - å¤šä»»åŠ¡å…¬å¹³è°ƒåº¦
// - å…¨å±€å¹¶å‘æ§åˆ¶
// - é¢„æ³¨å†Œæœºåˆ¶

use crate::auth::UserAuth;
use crate::config::{UploadConfig, VipType};
use crate::netdisk::NetdiskClient;
use crate::persistence::{
    PersistenceManager, TaskMetadata, TaskPersistenceStatus, TaskType, UploadRecoveryInfo,
};
use crate::server::events::{ProgressThrottler, TaskEvent, UploadEvent};
use crate::server::websocket::WebSocketManager;
use crate::uploader::{
    calculate_upload_task_max_chunks, FolderScanner, PcsServerHealthManager, ScanOptions,
    UploadChunkManager, UploadChunkScheduler, UploadEngine, UploadTask, UploadTaskScheduleInfo,
    UploadTaskStatus,
};
use anyhow::{Context, Result};
use dashmap::DashMap;
use std::collections::VecDeque;
use std::path::{Path, PathBuf};
use std::sync::atomic::{AtomicBool, AtomicU64, AtomicUsize, Ordering};
use std::sync::Arc;
use tokio::sync::{Mutex, RwLock, Semaphore};
use tokio_util::sync::CancellationToken;
use tracing::{error, info, warn};

/// ä¸Šä¼ ä»»åŠ¡ä¿¡æ¯ï¼ˆç”¨äºè°ƒåº¦ï¼‰
#[derive(Debug, Clone)]
pub struct UploadTaskInfo {
    /// ä»»åŠ¡
    pub task: Arc<Mutex<UploadTask>>,
    /// åˆ†ç‰‡ç®¡ç†å™¨
    pub chunk_manager: Arc<Mutex<UploadChunkManager>>,
    /// å–æ¶ˆä»¤ç‰Œ
    pub cancel_token: CancellationToken,
    /// æœ€å¤§å¹¶å‘åˆ†ç‰‡æ•°ï¼ˆæ ¹æ®æ–‡ä»¶å¤§å°è®¡ç®—ï¼‰
    pub max_concurrent_chunks: usize,
    /// å½“å‰æ´»è·ƒåˆ†ç‰‡æ•°
    pub active_chunk_count: Arc<AtomicUsize>,
    /// æ˜¯å¦æš‚åœ
    pub is_paused: Arc<AtomicBool>,
    /// å·²ä¸Šä¼ å­—èŠ‚æ•°ï¼ˆç”¨äºè°ƒåº¦å™¨æ¨¡å¼ï¼‰
    pub uploaded_bytes: Arc<AtomicU64>,
    /// ä¸Šæ¬¡é€Ÿåº¦è®¡ç®—æ—¶é—´
    pub last_speed_time: Arc<Mutex<std::time::Instant>>,
    /// ä¸Šæ¬¡é€Ÿåº¦è®¡ç®—å­—èŠ‚æ•°
    pub last_speed_bytes: Arc<AtomicU64>,
    /// ğŸ”¥ æ¢å¤çš„ upload_idï¼ˆå¦‚æœä»»åŠ¡æ˜¯ä»æŒä¹…åŒ–æ¢å¤çš„ï¼‰
    pub restored_upload_id: Option<String>,
}

/// ä¸Šä¼ ç®¡ç†å™¨
pub struct UploadManager {
    /// ç½‘ç›˜å®¢æˆ·ç«¯
    client: NetdiskClient,
    /// ç”¨æˆ· VIP ç±»å‹
    vip_type: VipType,
    /// æ‰€æœ‰ä»»åŠ¡ï¼ˆtask_id -> TaskInfoï¼‰- ä½¿ç”¨ Arc åŒ…è£…ä»¥æ”¯æŒè·¨çº¿ç¨‹å…±äº«
    tasks: Arc<DashMap<String, UploadTaskInfo>>,
    /// ç­‰å¾…é˜Ÿåˆ—ï¼ˆtask_id åˆ—è¡¨ï¼ŒFIFOï¼‰
    waiting_queue: Arc<RwLock<VecDeque<String>>>,
    /// å…¨å±€å¹¶å‘æ§åˆ¶ä¿¡å·é‡ï¼ˆç”¨äºç‹¬ç«‹æ¨¡å¼ï¼‰
    #[allow(dead_code)]
    global_semaphore: Arc<Semaphore>,
    /// æœåŠ¡å™¨å¥åº·ç®¡ç†å™¨
    server_health: Arc<PcsServerHealthManager>,
    /// å…¨å±€è°ƒåº¦å™¨ï¼ˆï¼‰
    scheduler: Option<Arc<UploadChunkScheduler>>,
    /// æ˜¯å¦ä½¿ç”¨è°ƒåº¦å™¨æ¨¡å¼
    use_scheduler: bool,
    /// æœ€å¤§åŒæ—¶ä¸Šä¼ ä»»åŠ¡æ•°ï¼ˆåŠ¨æ€å¯è°ƒæ•´ï¼‰
    max_concurrent_tasks: Arc<AtomicUsize>,
    /// æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆåŠ¨æ€å¯è°ƒæ•´ï¼‰
    max_retries: Arc<AtomicUsize>,
    /// ğŸ”¥ æŒä¹…åŒ–ç®¡ç†å™¨å¼•ç”¨ï¼ˆä½¿ç”¨å•é”ç»“æ„é¿å…æ­»é”ï¼‰
    persistence_manager: Arc<Mutex<Option<Arc<Mutex<PersistenceManager>>>>>,
    /// ğŸ”¥ WebSocket ç®¡ç†å™¨
    ws_manager: Arc<RwLock<Option<Arc<WebSocketManager>>>>,
}

impl UploadManager {
    /// åˆ›å»ºæ–°çš„ä¸Šä¼ ç®¡ç†å™¨ï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼‰
    pub fn new(client: NetdiskClient, user_auth: &UserAuth) -> Self {
        Self::new_with_config(client, user_auth, &UploadConfig::default())
    }

    /// åˆ›å»ºä¸Šä¼ ç®¡ç†å™¨ï¼ˆä»é…ç½®è¯»å–å‚æ•°ï¼‰
    ///
    /// # å‚æ•°
    /// * `client` - ç½‘ç›˜å®¢æˆ·ç«¯
    /// * `user_auth` - ç”¨æˆ·è®¤è¯ä¿¡æ¯
    /// * `config` - ä¸Šä¼ é…ç½®
    pub fn new_with_config(
        client: NetdiskClient,
        user_auth: &UserAuth,
        config: &UploadConfig,
    ) -> Self {
        Self::new_with_full_options(client, user_auth, config, true)
    }

    /// åˆ›å»ºä¸Šä¼ ç®¡ç†å™¨ï¼ˆå®Œæ•´é€‰é¡¹ï¼‰
    ///
    /// # å‚æ•°
    /// * `client` - ç½‘ç›˜å®¢æˆ·ç«¯
    /// * `user_auth` - ç”¨æˆ·è®¤è¯ä¿¡æ¯
    /// * `config` - ä¸Šä¼ é…ç½®
    /// * `use_scheduler` - æ˜¯å¦ä½¿ç”¨å…¨å±€è°ƒåº¦å™¨æ¨¡å¼
    pub fn new_with_full_options(
        client: NetdiskClient,
        user_auth: &UserAuth,
        config: &UploadConfig,
        use_scheduler: bool,
    ) -> Self {
        let max_global_threads = config.max_global_threads;
        let max_concurrent_tasks = config.max_concurrent_tasks;
        let max_retries = config.max_retries as usize;

        // ä» user_auth è·å– VIP ç±»å‹
        let vip_type = VipType::from_u32(user_auth.vip_type.unwrap_or(0));

        // åˆ›å»ºæœåŠ¡å™¨å¥åº·ç®¡ç†å™¨
        let servers = vec![
            "d.pcs.baidu.com".to_string(),
            "c.pcs.baidu.com".to_string(),
            "pcs.baidu.com".to_string(),
        ];
        let server_health = Arc::new(PcsServerHealthManager::from_servers(servers));

        // åˆ›å»ºè°ƒåº¦å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        let scheduler = if use_scheduler {
            info!(
                "ä¸Šä¼ ç®¡ç†å™¨ä½¿ç”¨è°ƒåº¦å™¨æ¨¡å¼: å…¨å±€çº¿ç¨‹æ•°={}, æœ€å¤§ä»»åŠ¡æ•°={}, æœ€å¤§é‡è¯•={}",
                max_global_threads, max_concurrent_tasks, max_retries
            );
            Some(Arc::new(UploadChunkScheduler::new_with_config(
                max_global_threads,
                max_concurrent_tasks,
                max_retries as u32,
            )))
        } else {
            info!(
                "ä¸Šä¼ ç®¡ç†å™¨ä½¿ç”¨ç‹¬ç«‹æ¨¡å¼: å…¨å±€çº¿ç¨‹æ•°={}, æœ€å¤§ä»»åŠ¡æ•°={}, æœ€å¤§é‡è¯•={}",
                max_global_threads, max_concurrent_tasks, max_retries
            );
            None
        };

        let waiting_queue = Arc::new(RwLock::new(VecDeque::new()));
        let max_concurrent_tasks_atomic = Arc::new(AtomicUsize::new(max_concurrent_tasks));
        let max_retries_atomic = Arc::new(AtomicUsize::new(max_retries));

        let tasks = Arc::new(DashMap::new());

        let manager = Self {
            client,
            vip_type,
            tasks: tasks.clone(),
            waiting_queue: waiting_queue.clone(),
            global_semaphore: Arc::new(Semaphore::new(max_global_threads)),
            server_health,
            scheduler: scheduler.clone(),
            use_scheduler,
            max_concurrent_tasks: max_concurrent_tasks_atomic,
            max_retries: max_retries_atomic,
            persistence_manager: Arc::new(Mutex::new(None)),
            ws_manager: Arc::new(RwLock::new(None)),
        };

        // å¯åŠ¨åå°ä»»åŠ¡ï¼šå®šæœŸæ£€æŸ¥å¹¶å¯åŠ¨ç­‰å¾…é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡
        if use_scheduler {
            manager.start_waiting_queue_monitor();
        }

        manager
    }

    /// åŠ¨æ€æ›´æ–°æœ€å¤§å…¨å±€çº¿ç¨‹æ•°
    pub fn update_max_threads(&self, new_max: usize) {
        if let Some(scheduler) = &self.scheduler {
            scheduler.update_max_threads(new_max);
        }
        info!("ğŸ”§ ä¸Šä¼ ç®¡ç†å™¨: åŠ¨æ€è°ƒæ•´å…¨å±€æœ€å¤§çº¿ç¨‹æ•°ä¸º {}", new_max);
    }

    /// åŠ¨æ€æ›´æ–°æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°
    pub fn update_max_concurrent_tasks(&self, new_max: usize) {
        self.max_concurrent_tasks.store(new_max, Ordering::SeqCst);
        if let Some(scheduler) = &self.scheduler {
            scheduler.update_max_concurrent_tasks(new_max);
        }
        info!("ğŸ”§ ä¸Šä¼ ç®¡ç†å™¨: åŠ¨æ€è°ƒæ•´æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°ä¸º {}", new_max);
    }

    /// åŠ¨æ€æ›´æ–°æœ€å¤§é‡è¯•æ¬¡æ•°
    pub fn update_max_retries(&self, new_max: u32) {
        self.max_retries.store(new_max as usize, Ordering::SeqCst);
        if let Some(scheduler) = &self.scheduler {
            scheduler.update_max_retries(new_max);
        }
        info!("ğŸ”§ ä¸Šä¼ ç®¡ç†å™¨: åŠ¨æ€è°ƒæ•´æœ€å¤§é‡è¯•æ¬¡æ•°ä¸º {}", new_max);
    }

    /// ğŸ”¥ è®¾ç½® WebSocket ç®¡ç†å™¨
    pub async fn set_ws_manager(&self, ws_manager: Arc<WebSocketManager>) {
        let mut ws = self.ws_manager.write().await;
        *ws = Some(ws_manager);
        info!("ä¸Šä¼ ç®¡ç†å™¨å·²è®¾ç½® WebSocket ç®¡ç†å™¨");
    }

    /// ğŸ”¥ å‘å¸ƒä¸Šä¼ äº‹ä»¶
    async fn publish_event(&self, event: UploadEvent) {
        let ws = self.ws_manager.read().await;
        if let Some(ref ws) = *ws {
            ws.send_if_subscribed(TaskEvent::Upload(event), None);
        }
    }

    /// è·å–å½“å‰æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°
    pub fn max_concurrent_tasks(&self) -> usize {
        self.max_concurrent_tasks.load(Ordering::SeqCst)
    }

    /// è·å–å½“å‰æœ€å¤§é‡è¯•æ¬¡æ•°
    pub fn max_retries(&self) -> u32 {
        self.max_retries.load(Ordering::SeqCst) as u32
    }

    /// è·å–è°ƒåº¦å™¨å¼•ç”¨
    pub fn scheduler(&self) -> Option<Arc<UploadChunkScheduler>> {
        self.scheduler.clone()
    }

    /// ğŸ”¥ è®¾ç½®æŒä¹…åŒ–ç®¡ç†å™¨
    ///
    /// ç”± AppState åœ¨åˆå§‹åŒ–æ—¶è°ƒç”¨ï¼Œæ³¨å…¥æŒä¹…åŒ–ç®¡ç†å™¨
    pub async fn set_persistence_manager(&self, pm: Arc<Mutex<PersistenceManager>>) {
        let mut lock = self.persistence_manager.lock().await;
        *lock = Some(pm);
        info!("ä¸Šä¼ ç®¡ç†å™¨å·²è®¾ç½®æŒä¹…åŒ–ç®¡ç†å™¨");
    }

    /// è·å–æŒä¹…åŒ–ç®¡ç†å™¨å¼•ç”¨çš„å…‹éš†
    pub async fn persistence_manager(&self) -> Option<Arc<Mutex<PersistenceManager>>> {
        self.persistence_manager.lock().await.clone()
    }

    /// åˆ›å»ºä¸Šä¼ ä»»åŠ¡
    ///
    /// # å‚æ•°
    /// * `local_path` - æœ¬åœ°æ–‡ä»¶è·¯å¾„
    /// * `remote_path` - ç½‘ç›˜ç›®æ ‡è·¯å¾„
    ///
    /// # è¿”å›
    /// ä»»åŠ¡ID
    pub async fn create_task(&self, local_path: PathBuf, remote_path: String) -> Result<String> {
        // è·å–æ–‡ä»¶å¤§å°
        let metadata = tokio::fs::metadata(&local_path)
            .await
            .context(format!("æ— æ³•è·å–æ–‡ä»¶å…ƒæ•°æ®: {:?}", local_path))?;

        if metadata.is_dir() {
            return Err(anyhow::anyhow!(
                "ä¸æ”¯æŒç›´æ¥ä¸Šä¼ ç›®å½•ï¼Œè¯·ä½¿ç”¨ create_folder_task"
            ));
        }

        let file_size = metadata.len();

        // åˆ›å»ºä»»åŠ¡
        let task = UploadTask::new(local_path.clone(), remote_path.clone(), file_size);
        let task_id = task.id.clone();

        // åˆ›å»ºåˆ†ç‰‡ç®¡ç†å™¨ï¼ˆä½¿ç”¨ç”¨æˆ·çš„ VIP ç­‰çº§è®¡ç®—åˆ†ç‰‡å¤§å°ï¼‰
        let chunk_manager = UploadChunkManager::with_vip_type(file_size, self.vip_type);

        // è®¡ç®—æœ€å¤§å¹¶å‘åˆ†ç‰‡æ•°
        let max_concurrent_chunks = calculate_upload_task_max_chunks(file_size);

        // è·å–åˆ†ç‰‡ä¿¡æ¯ï¼ˆç”¨äºæŒä¹…åŒ–ï¼‰
        let total_chunks = chunk_manager.chunk_count();
        let chunk_size =
            crate::uploader::calculate_recommended_chunk_size(file_size, self.vip_type);

        info!(
            "åˆ›å»ºä¸Šä¼ ä»»åŠ¡: id={}, local={:?}, remote={}, size={}, chunks={}, max_concurrent={}",
            task_id, local_path, remote_path, file_size, total_chunks, max_concurrent_chunks
        );

        // ğŸ”¥ æ³¨å†Œä»»åŠ¡åˆ°æŒä¹…åŒ–ç®¡ç†å™¨
        if let Some(pm_arc) = self
            .persistence_manager
            .lock()
            .await
            .as_ref()
            .map(|pm| pm.clone())
        {
            if let Err(e) = pm_arc.lock().await.register_upload_task(
                task_id.clone(),
                local_path.clone(),
                remote_path.clone(),
                file_size,
                chunk_size,
                total_chunks,
            ) {
                warn!("æ³¨å†Œä¸Šä¼ ä»»åŠ¡åˆ°æŒä¹…åŒ–ç®¡ç†å™¨å¤±è´¥: {}", e);
            }
        }

        // ä¿å­˜ä»»åŠ¡ä¿¡æ¯
        let task_info = UploadTaskInfo {
            task: Arc::new(Mutex::new(task)),
            chunk_manager: Arc::new(Mutex::new(chunk_manager)),
            cancel_token: CancellationToken::new(),
            max_concurrent_chunks,
            active_chunk_count: Arc::new(AtomicUsize::new(0)),
            is_paused: Arc::new(AtomicBool::new(false)),
            uploaded_bytes: Arc::new(AtomicU64::new(0)),
            last_speed_time: Arc::new(Mutex::new(std::time::Instant::now())),
            last_speed_bytes: Arc::new(AtomicU64::new(0)),
            restored_upload_id: None, // æ–°åˆ›å»ºçš„ä»»åŠ¡æ²¡æœ‰æ¢å¤çš„ upload_id
        };

        self.tasks.insert(task_id.clone(), task_info);

        // ğŸ”¥ å‘é€ä»»åŠ¡åˆ›å»ºäº‹ä»¶
        self.publish_event(UploadEvent::Created {
            task_id: task_id.clone(),
            local_path: local_path.to_string_lossy().to_string(),
            remote_path,
            total_size: file_size,
        })
            .await;

        Ok(task_id)
    }

    /// æ‰¹é‡åˆ›å»ºä¸Šä¼ ä»»åŠ¡
    pub async fn create_batch_tasks(&self, files: Vec<(PathBuf, String)>) -> Result<Vec<String>> {
        let mut task_ids = Vec::with_capacity(files.len());

        for (local_path, remote_path) in files {
            match self.create_task(local_path.clone(), remote_path).await {
                Ok(task_id) => {
                    task_ids.push(task_id);
                }
                Err(e) => {
                    warn!("åˆ›å»ºä»»åŠ¡å¤±è´¥: {:?}, é”™è¯¯: {}", local_path, e);
                }
            }
        }

        Ok(task_ids)
    }

    /// åˆ›å»ºæ–‡ä»¶å¤¹ä¸Šä¼ ä»»åŠ¡
    ///
    /// # å‚æ•°
    /// * `local_folder` - æœ¬åœ°æ–‡ä»¶å¤¹è·¯å¾„
    /// * `remote_folder` - ç½‘ç›˜ç›®æ ‡æ–‡ä»¶å¤¹è·¯å¾„
    /// * `scan_options` - æ‰«æé€‰é¡¹ï¼ˆå¯é€‰ï¼‰
    ///
    /// # è¿”å›
    /// æ‰€æœ‰åˆ›å»ºçš„ä»»åŠ¡IDåˆ—è¡¨
    ///
    /// # è¯´æ˜
    /// - ä¼šé€’å½’æ‰«ææœ¬åœ°æ–‡ä»¶å¤¹
    /// - ä¿æŒç›®å½•ç»“æ„
    /// - è‡ªåŠ¨åˆ›å»ºæ‰¹é‡ä¸Šä¼ ä»»åŠ¡
    pub async fn create_folder_task<P: AsRef<Path>>(
        &self,
        local_folder: P,
        remote_folder: String,
        scan_options: Option<ScanOptions>,
    ) -> Result<Vec<String>> {
        let local_folder = local_folder.as_ref();

        info!(
            "å¼€å§‹åˆ›å»ºæ–‡ä»¶å¤¹ä¸Šä¼ ä»»åŠ¡: local={:?}, remote={}",
            local_folder, remote_folder
        );

        // ä½¿ç”¨æ–‡ä»¶å¤¹æ‰«æå™¨æ‰«ææ–‡ä»¶
        let scanner = if let Some(options) = scan_options {
            FolderScanner::with_options(options)
        } else {
            FolderScanner::new()
        };

        let scanned_files = scanner.scan(local_folder)?;

        if scanned_files.is_empty() {
            return Err(anyhow::anyhow!("æ–‡ä»¶å¤¹ä¸ºç©ºæˆ–æ— å¯ä¸Šä¼ æ–‡ä»¶"));
        }

        info!("æ‰«æåˆ° {} ä¸ªæ–‡ä»¶ï¼Œå¼€å§‹åˆ›å»ºä¸Šä¼ ä»»åŠ¡", scanned_files.len());

        // å‡†å¤‡æ‰¹é‡ä»»åŠ¡
        let mut tasks = Vec::with_capacity(scanned_files.len());

        for file in scanned_files {
            // æ„å»ºè¿œç¨‹è·¯å¾„ï¼šremote_folder + relative_path
            let remote_path = if remote_folder.ends_with('/') {
                format!("{}{}", remote_folder, file.relative_path.to_string_lossy())
            } else {
                format!("{}/{}", remote_folder, file.relative_path.to_string_lossy())
            };

            // ç»Ÿä¸€è·¯å¾„åˆ†éš”ç¬¦ä¸º Unix é£æ ¼ï¼ˆç™¾åº¦ç½‘ç›˜ä½¿ç”¨ /ï¼‰
            let remote_path = remote_path.replace('\\', "/");

            tasks.push((file.local_path, remote_path));
        }

        // æ‰¹é‡åˆ›å»ºä»»åŠ¡
        let task_ids = self.create_batch_tasks(tasks).await?;

        info!("æ–‡ä»¶å¤¹ä¸Šä¼ ä»»åŠ¡åˆ›å»ºå®Œæˆ: æˆåŠŸ {} ä¸ª", task_ids.len());

        Ok(task_ids)
    }

    /// å¼€å§‹ä¸Šä¼ ä»»åŠ¡
    ///
    /// æ ¹æ® `use_scheduler` é…ç½®é€‰æ‹©æ‰§è¡Œæ¨¡å¼ï¼š
    /// - è°ƒåº¦å™¨æ¨¡å¼ï¼šå°†ä»»åŠ¡æ³¨å†Œåˆ°å…¨å±€è°ƒåº¦å™¨ï¼Œç”±è°ƒåº¦å™¨ç»Ÿä¸€è°ƒåº¦
    /// - ç‹¬ç«‹æ¨¡å¼ï¼šç›´æ¥å¯åŠ¨ UploadEngine æ‰§è¡Œä¸Šä¼ 
    pub async fn start_task(&self, task_id: &str) -> Result<()> {
        let task_info = self
            .tasks
            .get(task_id)
            .ok_or_else(|| anyhow::anyhow!("ä»»åŠ¡ä¸å­˜åœ¨: {}", task_id))?;

        // æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
        let (local_path, remote_path, total_size) = {
            let task = task_info.task.lock().await;
            match task.status {
                UploadTaskStatus::Pending | UploadTaskStatus::Paused => {}
                UploadTaskStatus::Uploading | UploadTaskStatus::CheckingRapid => {
                    return Err(anyhow::anyhow!("ä»»åŠ¡å·²åœ¨ä¸Šä¼ ä¸­"));
                }
                UploadTaskStatus::Completed | UploadTaskStatus::RapidUploadSuccess => {
                    return Err(anyhow::anyhow!("ä»»åŠ¡å·²å®Œæˆ"));
                }
                UploadTaskStatus::Failed => {
                    // å…è®¸é‡è¯•å¤±è´¥çš„ä»»åŠ¡
                }
            }
            (
                task.local_path.clone(),
                task.remote_path.clone(),
                task.total_size,
            )
        };

        // åŠ¨æ€è·å–ä¸Šä¼ æœåŠ¡å™¨åˆ—è¡¨
        match self.client.locate_upload().await {
            Ok(servers) => {
                if !servers.is_empty() {
                    self.server_health.update_servers(servers);
                }
            }
            Err(e) => {
                warn!("è·å–ä¸Šä¼ æœåŠ¡å™¨åˆ—è¡¨å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æœåŠ¡å™¨: {}", e);
            }
        }

        // æ ¹æ®æ¨¡å¼é€‰æ‹©å¯åŠ¨æ–¹å¼
        if self.use_scheduler && self.scheduler.is_some() {
            self.start_task_with_scheduler(task_id, &task_info, local_path, remote_path, total_size)
                .await
        } else {
            self.start_task_standalone(task_id, &task_info).await
        }
    }

    /// è°ƒåº¦å™¨æ¨¡å¼å¯åŠ¨ä»»åŠ¡
    async fn start_task_with_scheduler(
        &self,
        task_id: &str,
        task_info: &dashmap::mapref::one::Ref<'_, String, UploadTaskInfo>,
        local_path: PathBuf,
        remote_path: String,
        total_size: u64,
    ) -> Result<()> {
        let scheduler = self.scheduler.as_ref().unwrap();

        // é¢„æ³¨å†Œæ£€æŸ¥
        if !scheduler.pre_register().await {
            // åŠ å…¥ç­‰å¾…é˜Ÿåˆ—è€Œä¸æ˜¯è¿”å›é”™è¯¯
            self.waiting_queue
                .write()
                .await
                .push_back(task_id.to_string());

            info!(
                "ä¸Šä¼ ä»»åŠ¡ {} åŠ å…¥ç­‰å¾…é˜Ÿåˆ—ï¼ˆç³»ç»Ÿç­‰å¾…ï¼‰(æ´»è·ƒä»»åŠ¡æ•°å·²è¾¾ä¸Šé™: {})",
                task_id,
                self.max_concurrent_tasks()
            );
            return Ok(());
        }

        // å…‹éš†éœ€è¦çš„æ•°æ®
        let task = task_info.task.clone();
        let chunk_manager = task_info.chunk_manager.clone();
        let cancel_token = task_info.cancel_token.clone();
        let is_paused = task_info.is_paused.clone();
        let active_chunk_count = task_info.active_chunk_count.clone();
        let max_concurrent_chunks = task_info.max_concurrent_chunks;
        let uploaded_bytes = task_info.uploaded_bytes.clone();
        let last_speed_time = task_info.last_speed_time.clone();
        let last_speed_bytes = task_info.last_speed_bytes.clone();
        let server_health = self.server_health.clone();
        let client = self.client.clone();
        let scheduler = scheduler.clone();
        let task_id_string = task_id.to_string();
        let vip_type = self.vip_type;
        let persistence_manager = self.persistence_manager.lock().await.clone();
        // ğŸ”¥ æ£€æŸ¥æ˜¯å¦æœ‰æ¢å¤çš„ upload_id
        let restored_upload_id = task_info.restored_upload_id.clone();
        // ğŸ”¥ è·å– WebSocket ç®¡ç†å™¨
        let ws_manager = self.ws_manager.read().await.clone();
        // ğŸ”¥ å…‹éš† tasks å¼•ç”¨ï¼Œç”¨äºæ›´æ–° restored_upload_id
        let tasks = self.tasks.clone();

        // åœ¨åå°æ‰§è¡Œ precreate å¹¶æ³¨å†Œåˆ°è°ƒåº¦å™¨
        tokio::spawn(async move {
            info!("å¼€å§‹å‡†å¤‡ä¸Šä¼ ä»»åŠ¡: {}", task_id_string);

            // æ ‡è®°ä¸ºä¸Šä¼ ä¸­
            {
                let mut t = task.lock().await;
                t.mark_uploading();
            }

            // 1. è®¡ç®— block_listï¼ˆå¿…é¡»é‡æ–°è®¡ç®—ï¼Œå› ä¸ºå®ƒæ˜¯æŒ‰ 4MB å›ºå®šå¤§å°è®¡ç®—çš„ï¼‰
            let block_list = match crate::uploader::RapidUploadChecker::calculate_block_list(
                &local_path,
                vip_type,
            )
                .await
            {
                Ok(bl) => bl,
                Err(e) => {
                    let error_msg = format!("è®¡ç®— block_list å¤±è´¥: {}", e);
                    error!("{}", error_msg);
                    scheduler.cancel_pre_register();

                    let mut t = task.lock().await;
                    t.mark_failed(error_msg.clone());
                    drop(t);

                    // ğŸ”¥ å‘å¸ƒä»»åŠ¡å¤±è´¥äº‹ä»¶
                    if let Some(ref ws) = ws_manager {
                        ws.send_if_subscribed(
                            TaskEvent::Upload(UploadEvent::Failed {
                                task_id: task_id_string.clone(),
                                error: error_msg.clone(),
                            }),
                            None,
                        );
                    }

                    // ğŸ”¥ æ›´æ–°æŒä¹…åŒ–é”™è¯¯ä¿¡æ¯
                    if let Some(ref pm) = persistence_manager {
                        if let Err(e) = pm.lock().await.update_task_error(&task_id_string, error_msg) {
                            warn!("æ›´æ–°ä¸Šä¼ ä»»åŠ¡é”™è¯¯ä¿¡æ¯å¤±è´¥: {}", e);
                        }
                    }

                    return;
                }
            };

            // 2. æ£€æŸ¥æ˜¯å¦æœ‰æ¢å¤çš„ upload_id
            let upload_id = if let Some(restored_id) = restored_upload_id {
                info!(
                    "ä½¿ç”¨æ¢å¤çš„ upload_id: {} (å¦‚æœåˆå¹¶å¤±è´¥ï¼Œè¯´æ˜å·²è¿‡æœŸï¼Œéœ€è¦é‡æ–°ä¸Šä¼ )",
                    restored_id
                );
                restored_id
            } else {
                // æ²¡æœ‰æ¢å¤çš„ upload_idï¼Œéœ€è¦è°ƒç”¨ precreate
                let precreate_response = match client
                    .precreate(&remote_path, total_size, &block_list)
                    .await
                {
                    Ok(resp) => resp,
                    Err(e) => {
                        let error_msg = format!("é¢„åˆ›å»ºæ–‡ä»¶å¤±è´¥: {}", e);
                        error!("{}", error_msg);
                        scheduler.cancel_pre_register();

                        let mut t = task.lock().await;
                        t.mark_failed(error_msg.clone());
                        drop(t);

                        // ğŸ”¥ å‘å¸ƒä»»åŠ¡å¤±è´¥äº‹ä»¶
                        if let Some(ref ws) = ws_manager {
                            ws.send_if_subscribed(
                                TaskEvent::Upload(UploadEvent::Failed {
                                    task_id: task_id_string.clone(),
                                    error: error_msg.clone(),
                                }),
                                None,
                            );
                        }

                        // ğŸ”¥ æ›´æ–°æŒä¹…åŒ–é”™è¯¯ä¿¡æ¯
                        if let Some(ref pm) = persistence_manager {
                            if let Err(e) = pm.lock().await.update_task_error(&task_id_string, error_msg) {
                                warn!("æ›´æ–°ä¸Šä¼ ä»»åŠ¡é”™è¯¯ä¿¡æ¯å¤±è´¥: {}", e);
                            }
                        }

                        return;
                    }
                };

                // æ£€æŸ¥ç§’ä¼ 
                if precreate_response.is_rapid_upload() {
                    info!("ç§’ä¼ æˆåŠŸ: {}", remote_path);
                    scheduler.cancel_pre_register();
                    let mut t = task.lock().await;
                    t.mark_rapid_upload_success();
                    return;
                }

                let new_upload_id = precreate_response.uploadid.clone();
                if new_upload_id.is_empty() {
                    let error_msg = "é¢„åˆ›å»ºå¤±è´¥ï¼šæœªè·å–åˆ° uploadid".to_string();
                    error!("{}", error_msg);
                    scheduler.cancel_pre_register();

                    let mut t = task.lock().await;
                    t.mark_failed(error_msg.clone());
                    drop(t);

                    // ğŸ”¥ å‘å¸ƒä»»åŠ¡å¤±è´¥äº‹ä»¶
                    if let Some(ref ws) = ws_manager {
                        ws.send_if_subscribed(
                            TaskEvent::Upload(UploadEvent::Failed {
                                task_id: task_id_string.clone(),
                                error: error_msg.clone(),
                            }),
                            None,
                        );
                    }

                    // ğŸ”¥ æ›´æ–°æŒä¹…åŒ–é”™è¯¯ä¿¡æ¯
                    if let Some(ref pm) = persistence_manager {
                        if let Err(e) = pm.lock().await.update_task_error(&task_id_string, error_msg) {
                            warn!("æ›´æ–°ä¸Šä¼ ä»»åŠ¡é”™è¯¯ä¿¡æ¯å¤±è´¥: {}", e);
                        }
                    }

                    return;
                }

                // ğŸ”¥ æ›´æ–°æŒä¹…åŒ–å…ƒæ•°æ®ä¸­çš„ upload_id
                if let Some(ref pm_arc) = persistence_manager {
                    if let Err(e) = pm_arc
                        .lock()
                        .await
                        .update_upload_id(&task_id_string, new_upload_id.clone())
                    {
                        warn!("æ›´æ–°ä¸Šä¼ ä»»åŠ¡ upload_id å¤±è´¥: {}", e);
                    }
                }

                // ğŸ”¥ æ›´æ–°å†…å­˜ä¸­çš„ restored_upload_idï¼ˆå…³é”®ä¿®å¤ï¼šæ”¯æŒæš‚åœæ¢å¤ï¼‰
                if let Some(mut task_info) = tasks.get_mut(&task_id_string) {
                    task_info.restored_upload_id = Some(new_upload_id.clone());
                    info!("âœ“ å·²ä¿å­˜ upload_id åˆ°ä»»åŠ¡ä¿¡æ¯ï¼Œæ”¯æŒæš‚åœæ¢å¤: {}", task_id_string);
                }

                new_upload_id
            };

            // 3. åˆ›å»ºè°ƒåº¦ä¿¡æ¯å¹¶æ³¨å†Œåˆ°è°ƒåº¦å™¨
            let schedule_info = UploadTaskScheduleInfo {
                task_id: task_id_string.clone(),
                task: task.clone(),
                chunk_manager,
                server_health,
                client,
                local_path,
                remote_path: remote_path.clone(),
                upload_id: upload_id.clone(),
                total_size,
                block_list,
                cancellation_token: cancel_token,
                is_paused,
                is_merging: Arc::new(AtomicBool::new(false)),
                active_chunk_count,
                max_concurrent_chunks,
                uploaded_bytes,
                last_speed_time,
                last_speed_bytes,
                persistence_manager,
                ws_manager,
                progress_throttler: Arc::new(ProgressThrottler::default()),
            };

            if let Err(e) = scheduler.register_task(schedule_info).await {
                error!("æ³¨å†Œä»»åŠ¡åˆ°è°ƒåº¦å™¨å¤±è´¥: {}", e);
                scheduler.cancel_pre_register();
                let mut t = task.lock().await;
                t.mark_failed(format!("æ³¨å†Œä»»åŠ¡å¤±è´¥: {}", e));
                return;
            }

            info!("ä¸Šä¼ ä»»åŠ¡å·²æ³¨å†Œåˆ°è°ƒåº¦å™¨: {}", task_id_string);

            // æ³¨æ„ï¼šè°ƒåº¦å™¨ä¼šè‡ªåŠ¨å¤„ç†åˆ†ç‰‡ä¸Šä¼ å’Œå®Œæˆ
            // è¿™é‡Œä¸éœ€è¦ç­‰å¾…ï¼Œè°ƒåº¦å™¨ä¼šåœ¨æ‰€æœ‰åˆ†ç‰‡å®Œæˆåè°ƒç”¨ create_file
        });

        Ok(())
    }

    /// ç‹¬ç«‹æ¨¡å¼å¯åŠ¨ä»»åŠ¡
    async fn start_task_standalone(
        &self,
        task_id: &str,
        task_info: &dashmap::mapref::one::Ref<'_, String, UploadTaskInfo>,
    ) -> Result<()> {
        // å…‹éš†éœ€è¦çš„æ•°æ®
        let task = task_info.task.clone();
        let chunk_manager = task_info.chunk_manager.clone();
        let cancel_token = task_info.cancel_token.clone();
        let server_health = self.server_health.clone();
        let client = self.client.clone();

        // åˆ›å»ºä¸Šä¼ å¼•æ“
        let engine = UploadEngine::new(
            client,
            task.clone(),
            chunk_manager,
            server_health,
            cancel_token,
            self.vip_type,
        );

        // åœ¨åå°å¯åŠ¨ä¸Šä¼ 
        let task_id_clone = task_id.to_string();
        tokio::spawn(async move {
            info!("å¼€å§‹ä¸Šä¼ ä»»åŠ¡: {}", task_id_clone);

            match engine.upload().await {
                Ok(()) => {
                    info!("ä¸Šä¼ ä»»åŠ¡å®Œæˆ: {}", task_id_clone);
                }
                Err(e) => {
                    error!("ä¸Šä¼ ä»»åŠ¡å¤±è´¥: {}, é”™è¯¯: {}", task_id_clone, e);
                    let mut task = task.lock().await;
                    task.mark_failed(e.to_string());
                }
            }
        });

        Ok(())
    }

    /// æš‚åœä¸Šä¼ ä»»åŠ¡
    pub async fn pause_task(&self, task_id: &str) -> Result<()> {
        let task_info = self
            .tasks
            .get(task_id)
            .ok_or_else(|| anyhow::anyhow!("ä»»åŠ¡ä¸å­˜åœ¨: {}", task_id))?;

        // è®¾ç½®æš‚åœæ ‡å¿—ï¼ˆè°ƒåº¦å™¨æ¨¡å¼ä½¿ç”¨ï¼‰
        task_info.is_paused.store(true, Ordering::SeqCst);

        let mut task = task_info.task.lock().await;

        match task.status {
            UploadTaskStatus::Uploading | UploadTaskStatus::CheckingRapid => {
                // ğŸ”¥ ä¿å­˜æ—§çŠ¶æ€ç”¨äºå‘å¸ƒ StatusChanged
                let old_status = format!("{:?}", task.status).to_lowercase();

                task.mark_paused();
                info!("æš‚åœä¸Šä¼ ä»»åŠ¡: {}", task_id);
                drop(task);

                // ğŸ”¥ å‘é€çŠ¶æ€å˜æ›´äº‹ä»¶
                self.publish_event(UploadEvent::StatusChanged {
                    task_id: task_id.to_string(),
                    old_status,
                    new_status: "paused".to_string(),
                })
                    .await;

                // ğŸ”¥ å‘é€æš‚åœäº‹ä»¶
                self.publish_event(UploadEvent::Paused {
                    task_id: task_id.to_string(),
                })
                    .await;
                Ok(())
            }
            _ => Err(anyhow::anyhow!("ä»»åŠ¡å½“å‰çŠ¶æ€ä¸æ”¯æŒæš‚åœ")),
        }
    }

    /// æ¢å¤ä¸Šä¼ ä»»åŠ¡
    pub async fn resume_task(&self, task_id: &str) -> Result<()> {
        let task_info = self
            .tasks
            .get(task_id)
            .ok_or_else(|| anyhow::anyhow!("ä»»åŠ¡ä¸å­˜åœ¨: {}", task_id))?;

        let old_status;
        {
            let task = task_info.task.lock().await;
            if task.status != UploadTaskStatus::Paused {
                return Err(anyhow::anyhow!("ä»»åŠ¡ä¸æ˜¯æš‚åœçŠ¶æ€"));
            }
            // ğŸ”¥ ä¿å­˜æ—§çŠ¶æ€
            old_status = format!("{:?}", task.status).to_lowercase();
        }

        // æ¸…é™¤æš‚åœæ ‡å¿—ï¼ˆè°ƒåº¦å™¨æ¨¡å¼ä½¿ç”¨ï¼‰
        task_info.is_paused.store(false, Ordering::SeqCst);

        // ğŸ”¥ å‘é€çŠ¶æ€å˜æ›´äº‹ä»¶
        self.publish_event(UploadEvent::StatusChanged {
            task_id: task_id.to_string(),
            old_status,
            new_status: "pending".to_string(),
        })
            .await;

        // ğŸ”¥ å‘é€æ¢å¤äº‹ä»¶
        self.publish_event(UploadEvent::Resumed {
            task_id: task_id.to_string(),
        })
            .await;

        // é‡æ–°å¼€å§‹ä»»åŠ¡
        self.start_task(task_id).await
    }

    /// å–æ¶ˆä¸Šä¼ ä»»åŠ¡
    pub async fn cancel_task(&self, task_id: &str) -> Result<()> {
        // ä»ç­‰å¾…é˜Ÿåˆ—ç§»é™¤ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        {
            let mut queue = self.waiting_queue.write().await;
            queue.retain(|id| id != task_id);
        }

        let task_info = self
            .tasks
            .get(task_id)
            .ok_or_else(|| anyhow::anyhow!("ä»»åŠ¡ä¸å­˜åœ¨: {}", task_id))?;

        // å‘é€å–æ¶ˆä¿¡å·
        task_info.cancel_token.cancel();

        // å¦‚æœä½¿ç”¨è°ƒåº¦å™¨æ¨¡å¼ï¼Œä¹Ÿä»è°ƒåº¦å™¨å–æ¶ˆ
        if let Some(scheduler) = &self.scheduler {
            scheduler.cancel_task(task_id).await;
        }

        // æ›´æ–°ä»»åŠ¡çŠ¶æ€
        let mut task = task_info.task.lock().await;
        task.mark_failed("ç”¨æˆ·å–æ¶ˆ".to_string());

        info!("å–æ¶ˆä¸Šä¼ ä»»åŠ¡: {}", task_id);

        drop(task);
        drop(task_info);

        // å°è¯•å¯åŠ¨ç­‰å¾…é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡
        self.try_start_waiting_tasks().await;

        Ok(())
    }

    /// åˆ é™¤ä¸Šä¼ ä»»åŠ¡
    pub async fn delete_task(&self, task_id: &str) -> Result<()> {
        // ä»ç­‰å¾…é˜Ÿåˆ—ç§»é™¤ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        {
            let mut queue = self.waiting_queue.write().await;
            queue.retain(|id| id != task_id);
        }

        // å…ˆå–æ¶ˆä»»åŠ¡
        if let Some(task_info) = self.tasks.get(task_id) {
            task_info.cancel_token.cancel();
        }

        // å¦‚æœä½¿ç”¨è°ƒåº¦å™¨æ¨¡å¼ï¼Œä¹Ÿä»è°ƒåº¦å™¨ç§»é™¤
        if let Some(scheduler) = &self.scheduler {
            scheduler.cancel_task(task_id).await;
        }

        // ç§»é™¤ä»»åŠ¡
        self.tasks.remove(task_id);

        // ğŸ”¥ æ¸…ç†æŒä¹…åŒ–æ–‡ä»¶
        if let Some(pm_arc) = self
            .persistence_manager
            .lock()
            .await
            .as_ref()
            .map(|pm| pm.clone())
        {
            if let Err(e) = pm_arc.lock().await.on_task_deleted(task_id) {
                warn!("æ¸…ç†ä¸Šä¼ ä»»åŠ¡æŒä¹…åŒ–æ–‡ä»¶å¤±è´¥: {}", e);
            }
        }

        info!("åˆ é™¤ä¸Šä¼ ä»»åŠ¡: {}", task_id);

        // ğŸ”¥ å‘é€åˆ é™¤äº‹ä»¶
        self.publish_event(UploadEvent::Deleted {
            task_id: task_id.to_string(),
        })
            .await;

        // å°è¯•å¯åŠ¨ç­‰å¾…é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡
        self.try_start_waiting_tasks().await;

        Ok(())
    }

    /// è·å–ä»»åŠ¡çŠ¶æ€
    pub async fn get_task(&self, task_id: &str) -> Option<UploadTask> {
        let task_info = self.tasks.get(task_id)?;
        let task = task_info.task.lock().await;
        Some(task.clone())
    }

    /// è·å–æ‰€æœ‰ä»»åŠ¡ï¼ˆåŒ…æ‹¬å½“å‰ä»»åŠ¡å’Œå†å²ä»»åŠ¡ï¼‰
    pub async fn get_all_tasks(&self) -> Vec<UploadTask> {
        let mut tasks = Vec::new();

        // è·å–å½“å‰ä»»åŠ¡
        for entry in self.tasks.iter() {
            let task = entry.task.lock().await;
            tasks.push(task.clone());
        }

        // ä»å†å²ç¼“å­˜è·å–å†å²ä»»åŠ¡
        if let Some(pm_arc) = self
            .persistence_manager
            .lock()
            .await
            .as_ref()
            .map(|pm| pm.clone())
        {
            let pm = pm_arc.lock().await;
            let history_cache = pm.history_cache();

            for entry in history_cache.iter() {
                let metadata = entry.value();

                // åªåŒ…å«ä¸Šä¼ ä»»åŠ¡ä¸”çŠ¶æ€ä¸ºå·²å®Œæˆ
                if metadata.task_type == TaskType::Upload
                    && metadata.status == Some(TaskPersistenceStatus::Completed)
                {
                    // æ’é™¤å·²åœ¨å½“å‰ä»»åŠ¡ä¸­çš„ï¼ˆé¿å…é‡å¤ï¼‰
                    if !self.tasks.contains_key(&metadata.task_id) {
                        if let Some(task) = Self::convert_history_to_task(metadata) {
                            tasks.push(task);
                        }
                    }
                }
            }
        }

        // æŒ‰åˆ›å»ºæ—¶é—´å€’åºæ’åº
        tasks.sort_by(|a, b| b.created_at.cmp(&a.created_at));

        tasks
    }

    /// å°†å†å²å…ƒæ•°æ®è½¬æ¢ä¸ºä¸Šä¼ ä»»åŠ¡
    fn convert_history_to_task(metadata: &TaskMetadata) -> Option<UploadTask> {
        // éªŒè¯å¿…è¦å­—æ®µ
        let local_path = metadata.source_path.clone()?;
        let remote_path = metadata.target_path.clone()?;
        let file_size = metadata.file_size.unwrap_or(0);

        Some(UploadTask {
            id: metadata.task_id.clone(),
            local_path,
            remote_path,
            total_size: file_size,
            uploaded_size: file_size, // å·²å®Œæˆçš„ä»»åŠ¡
            status: UploadTaskStatus::Completed,
            speed: 0,
            created_at: metadata.created_at.timestamp(),
            started_at: Some(metadata.created_at.timestamp()),
            completed_at: metadata.completed_at.map(|t| t.timestamp()),
            error: None,
            is_rapid_upload: false,
            content_md5: None,
            slice_md5: None,
            content_crc32: None,
            group_id: None,
            group_root: None,
            relative_path: None,
            total_chunks: metadata.total_chunks.unwrap_or(0),
            completed_chunks: metadata.total_chunks.unwrap_or(0), // å·²å®Œæˆçš„ä»»åŠ¡
        })
    }

    /// è·å–æ´»è·ƒä»»åŠ¡æ•°
    pub fn active_task_count(&self) -> usize {
        let mut count = 0;
        for entry in self.tasks.iter() {
            // è¿™é‡Œä½¿ç”¨ try_lock é¿å…é˜»å¡
            if let Ok(task) = entry.task.try_lock() {
                if matches!(
                    task.status,
                    UploadTaskStatus::Uploading | UploadTaskStatus::CheckingRapid
                ) {
                    count += 1;
                }
            }
        }
        count
    }

    /// æ¸…é™¤å·²å®Œæˆçš„ä»»åŠ¡
    pub async fn clear_completed(&self) -> usize {
        let mut to_remove = Vec::new();

        // 1. æ”¶é›†å†…å­˜ä¸­çš„å·²å®Œæˆä»»åŠ¡
        for entry in self.tasks.iter() {
            let task = entry.task.lock().await;
            if matches!(
                task.status,
                UploadTaskStatus::Completed | UploadTaskStatus::RapidUploadSuccess
            ) {
                to_remove.push(entry.key().clone());
            }
        }

        // 2. ä»å†…å­˜ä¸­ç§»é™¤
        let memory_count = to_remove.len();
        for task_id in &to_remove {
            self.tasks.remove(task_id);
        }

        // 3. ä»å†å²ç¼“å­˜å’Œå†å²æ–‡ä»¶ä¸­æ¸…é™¤å·²å®Œæˆä»»åŠ¡
        let mut history_count = 0;
        if let Some(pm_arc) = self.persistence_manager.lock().await.as_ref().map(|pm| pm.clone()) {
            let pm_guard = pm_arc.lock().await;
            let history_cache = pm_guard.history_cache();
            let wal_dir = pm_guard.wal_dir().clone();

            // æ”¶é›†å†å²ç¼“å­˜ä¸­çš„å·²å®Œæˆä¸Šä¼ ä»»åŠ¡
            let mut history_to_remove = Vec::new();
            for entry in history_cache.iter() {
                let metadata = entry.value();
                if metadata.task_type == TaskType::Upload
                    && metadata.status == Some(TaskPersistenceStatus::Completed)
                {
                    history_to_remove.push(metadata.task_id.clone());
                }
            }

            // ä»å†å²ç¼“å­˜ä¸­ç§»é™¤
            for task_id in &history_to_remove {
                history_cache.remove(task_id);
            }

            history_count = history_to_remove.len();

            // é‡Šæ”¾ pm_guardï¼Œé¿å…é•¿æ—¶é—´æŒé”
            drop(pm_guard);

            // ä»å†å²æ–‡ä»¶ä¸­åˆ é™¤ï¼ˆæ‰¹é‡æ“ä½œï¼‰
            for task_id in &history_to_remove {
                if let Err(e) = crate::persistence::history::remove_from_history_file(&wal_dir, task_id) {
                    warn!("ä»å†å²æ–‡ä»¶åˆ é™¤ä»»åŠ¡å¤±è´¥: task_id={}, é”™è¯¯: {}", task_id, e);
                }
            }
        }

        let total_count = memory_count + history_count;
        info!(
            "æ¸…é™¤äº† {} ä¸ªå·²å®Œæˆçš„ä¸Šä¼ ä»»åŠ¡ï¼ˆå†…å­˜: {}, å†å²: {}ï¼‰",
            total_count, memory_count, history_count
        );
        total_count
    }

    /// æ¸…é™¤å¤±è´¥çš„ä»»åŠ¡
    pub async fn clear_failed(&self) -> usize {
        let mut removed = 0;
        let mut to_remove = Vec::new();

        for entry in self.tasks.iter() {
            let task = entry.task.lock().await;
            if matches!(task.status, UploadTaskStatus::Failed) {
                to_remove.push(entry.key().clone());
            }
        }

        for task_id in to_remove {
            self.tasks.remove(&task_id);
            removed += 1;
        }

        info!("æ¸…é™¤äº† {} ä¸ªå¤±è´¥çš„ä¸Šä¼ ä»»åŠ¡", removed);
        removed
    }

    /// å¼€å§‹æ‰€æœ‰å¾…å¤„ç†çš„ä»»åŠ¡
    pub async fn start_all_pending(&self) -> Result<usize> {
        let mut started = 0;
        let mut pending_ids = Vec::new();

        for entry in self.tasks.iter() {
            let task = entry.task.lock().await;
            if matches!(task.status, UploadTaskStatus::Pending) {
                pending_ids.push(entry.key().clone());
            }
        }

        for task_id in pending_ids {
            if let Err(e) = self.start_task(&task_id).await {
                warn!("å¯åŠ¨ä»»åŠ¡å¤±è´¥: {}, é”™è¯¯: {}", task_id, e);
            } else {
                started += 1;
            }
        }

        info!("å¯åŠ¨äº† {} ä¸ªå¾…å¤„ç†çš„ä¸Šä¼ ä»»åŠ¡", started);
        Ok(started)
    }

    /// å°è¯•ä»ç­‰å¾…é˜Ÿåˆ—å¯åŠ¨ä»»åŠ¡
    async fn try_start_waiting_tasks(&self) {
        if !self.use_scheduler {
            return;
        }

        let scheduler = match &self.scheduler {
            Some(s) => s,
            None => return,
        };

        loop {
            // æ£€æŸ¥æ˜¯å¦æœ‰ç©ºé—²ä½ç½®
            let active_count = scheduler.active_task_count().await;
            if active_count >= self.max_concurrent_tasks() {
                break;
            }

            // ä»ç­‰å¾…é˜Ÿåˆ—å–å‡ºä»»åŠ¡
            let task_id = {
                let mut queue = self.waiting_queue.write().await;
                queue.pop_front()
            };

            match task_id {
                Some(id) => {
                    info!("ä»ç­‰å¾…é˜Ÿåˆ—å¯åŠ¨ä¸Šä¼ ä»»åŠ¡: {}", id);
                    if let Err(e) = self.start_task(&id).await {
                        error!("å¯åŠ¨ç­‰å¾…ä¸Šä¼ ä»»åŠ¡å¤±è´¥: {}, é”™è¯¯: {}", id, e);
                    }
                }
                None => break, // é˜Ÿåˆ—ä¸ºç©º
            }
        }
    }

    /// å¯åŠ¨åå°ç›‘æ§ä»»åŠ¡ï¼šå®šæœŸæ£€æŸ¥å¹¶å¯åŠ¨ç­‰å¾…é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡
    ///
    /// è¿™ç¡®ä¿äº†å½“æ´»è·ƒä»»åŠ¡è‡ªç„¶å®Œæˆæ—¶ï¼Œç­‰å¾…é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡èƒ½è¢«è‡ªåŠ¨å¯åŠ¨
    fn start_waiting_queue_monitor(&self) {
        let waiting_queue = self.waiting_queue.clone();
        let scheduler = match &self.scheduler {
            Some(s) => s.clone(),
            None => return,
        };
        let tasks = self.tasks.clone();
        let client = self.client.clone();
        let server_health = self.server_health.clone();
        let vip_type = self.vip_type;
        let max_concurrent_tasks = self.max_concurrent_tasks.clone();
        let persistence_manager = self.persistence_manager.clone();
        let ws_manager = self.ws_manager.clone();

        tokio::spawn(async move {
            let mut interval = tokio::time::interval(tokio::time::Duration::from_secs(3));

            loop {
                interval.tick().await;

                // æ£€æŸ¥æ˜¯å¦æœ‰ç­‰å¾…ä»»åŠ¡
                let has_waiting = {
                    let queue = waiting_queue.read().await;
                    !queue.is_empty()
                };

                if !has_waiting {
                    continue;
                }

                // æ£€æŸ¥æ˜¯å¦æœ‰ç©ºé—²ä½ç½®
                let active_count = scheduler.active_task_count().await;
                if active_count >= max_concurrent_tasks.load(Ordering::SeqCst) {
                    continue;
                }

                // å°è¯•å¯åŠ¨ç­‰å¾…ä»»åŠ¡
                loop {
                    // å…ˆé¢„æ³¨å†Œï¼ŒæˆåŠŸæ‰ç»§ç»­
                    if !scheduler.pre_register().await {
                        break;
                    }

                    let task_id = {
                        let mut queue = waiting_queue.write().await;
                        queue.pop_front()
                    };

                    match task_id {
                        Some(id) => {
                            info!("ğŸ”„ åå°ç›‘æ§ï¼šä»ç­‰å¾…é˜Ÿåˆ—å¯åŠ¨ä¸Šä¼ ä»»åŠ¡ {} (å·²é¢„æ³¨å†Œ)", id);

                            // è·å–ä»»åŠ¡ä¿¡æ¯
                            let task_info_opt = tasks.get(&id);
                            if let Some(task_info) = task_info_opt {
                                // è·å–ä»»åŠ¡åŸºæœ¬ä¿¡æ¯
                                let (local_path, remote_path, total_size) = {
                                    let task = task_info.task.lock().await;
                                    (
                                        task.local_path.clone(),
                                        task.remote_path.clone(),
                                        task.total_size,
                                    )
                                };

                                // å…‹éš†éœ€è¦çš„æ•°æ®
                                let task = task_info.task.clone();
                                let chunk_manager = task_info.chunk_manager.clone();
                                let cancel_token = task_info.cancel_token.clone();
                                let is_paused = task_info.is_paused.clone();
                                let active_chunk_count = task_info.active_chunk_count.clone();
                                let max_concurrent_chunks = task_info.max_concurrent_chunks;
                                let uploaded_bytes = task_info.uploaded_bytes.clone();
                                let last_speed_time = task_info.last_speed_time.clone();
                                let last_speed_bytes = task_info.last_speed_bytes.clone();

                                drop(task_info); // é‡Šæ”¾ DashMap å¼•ç”¨

                                let server_health_clone = server_health.clone();
                                let client_clone = client.clone();
                                let scheduler_clone = scheduler.clone();
                                let task_id_clone = id.clone();
                                let pm_clone = persistence_manager.lock().await.clone();
                                let ws_manager_clone = ws_manager.read().await.clone();

                                // åœ¨åå°æ‰§è¡Œ precreate å¹¶æ³¨å†Œåˆ°è°ƒåº¦å™¨
                                tokio::spawn(async move {
                                    info!("åå°ç›‘æ§ï¼šå¼€å§‹å‡†å¤‡ä¸Šä¼ ä»»åŠ¡: {}", task_id_clone);

                                    // æ ‡è®°ä¸ºä¸Šä¼ ä¸­
                                    {
                                        let mut t = task.lock().await;
                                        t.mark_uploading();
                                    }

                                    // 1. è®¡ç®— block_list
                                    let block_list = match crate::uploader::RapidUploadChecker::calculate_block_list(&local_path, vip_type).await {
                                        Ok(bl) => bl,
                                        Err(e) => {
                                            error!("åå°ç›‘æ§ï¼šè®¡ç®— block_list å¤±è´¥: {}", e);
                                            scheduler_clone.cancel_pre_register();
                                            let mut t = task.lock().await;
                                            t.mark_failed(format!("è®¡ç®— block_list å¤±è´¥: {}", e));
                                            return;
                                        }
                                    };

                                    // 2. é¢„åˆ›å»ºæ–‡ä»¶
                                    let precreate_response = match client_clone
                                        .precreate(&remote_path, total_size, &block_list)
                                        .await
                                    {
                                        Ok(resp) => resp,
                                        Err(e) => {
                                            error!("åå°ç›‘æ§ï¼šé¢„åˆ›å»ºæ–‡ä»¶å¤±è´¥: {}", e);
                                            scheduler_clone.cancel_pre_register();
                                            let mut t = task.lock().await;
                                            t.mark_failed(format!("é¢„åˆ›å»ºæ–‡ä»¶å¤±è´¥: {}", e));
                                            return;
                                        }
                                    };

                                    // æ£€æŸ¥ç§’ä¼ 
                                    if precreate_response.is_rapid_upload() {
                                        info!("åå°ç›‘æ§ï¼šç§’ä¼ æˆåŠŸ: {}", remote_path);
                                        scheduler_clone.cancel_pre_register();
                                        let mut t = task.lock().await;
                                        t.mark_rapid_upload_success();
                                        return;
                                    }

                                    let upload_id = precreate_response.uploadid.clone();
                                    if upload_id.is_empty() {
                                        error!("åå°ç›‘æ§ï¼šé¢„åˆ›å»ºå¤±è´¥ï¼šæœªè·å–åˆ° uploadid");
                                        scheduler_clone.cancel_pre_register();
                                        let mut t = task.lock().await;
                                        t.mark_failed("é¢„åˆ›å»ºå¤±è´¥ï¼šæœªè·å–åˆ° uploadid".to_string());
                                        return;
                                    }

                                    // ğŸ”¥ æ›´æ–°æŒä¹…åŒ–å…ƒæ•°æ®ä¸­çš„ upload_id
                                    if let Some(ref pm_arc) = pm_clone {
                                        if let Err(e) = pm_arc
                                            .lock()
                                            .await
                                            .update_upload_id(&task_id_clone, upload_id.clone())
                                        {
                                            warn!("åå°ç›‘æ§ï¼šæ›´æ–°ä¸Šä¼ ä»»åŠ¡ upload_id å¤±è´¥: {}", e);
                                        }
                                    }

                                    // 3. åˆ›å»ºè°ƒåº¦ä¿¡æ¯å¹¶æ³¨å†Œåˆ°è°ƒåº¦å™¨
                                    let schedule_info = UploadTaskScheduleInfo {
                                        task_id: task_id_clone.clone(),
                                        task: task.clone(),
                                        chunk_manager,
                                        server_health: server_health_clone,
                                        client: client_clone,
                                        local_path: local_path.to_path_buf(),
                                        remote_path: remote_path.to_string(),
                                        upload_id: upload_id.clone(),
                                        total_size,
                                        block_list,
                                        cancellation_token: cancel_token,
                                        is_paused,
                                        is_merging: Arc::new(AtomicBool::new(false)),
                                        active_chunk_count,
                                        max_concurrent_chunks,
                                        uploaded_bytes,
                                        last_speed_time,
                                        last_speed_bytes,
                                        persistence_manager: pm_clone,
                                        ws_manager: ws_manager_clone,
                                        progress_throttler: Arc::new(ProgressThrottler::default()),
                                    };

                                    if let Err(e) =
                                        scheduler_clone.register_task(schedule_info).await
                                    {
                                        error!("åå°ç›‘æ§ï¼šæ³¨å†Œä»»åŠ¡åˆ°è°ƒåº¦å™¨å¤±è´¥: {}", e);
                                        scheduler_clone.cancel_pre_register();
                                        let mut t = task.lock().await;
                                        t.mark_failed(format!("æ³¨å†Œä»»åŠ¡å¤±è´¥: {}", e));
                                        return;
                                    }

                                    info!("åå°ç›‘æ§ï¼šä¸Šä¼ ä»»åŠ¡ {} å·²æ³¨å†Œåˆ°è°ƒåº¦å™¨", task_id_clone);
                                });
                            } else {
                                // ä»»åŠ¡ä¸å­˜åœ¨ï¼Œå–æ¶ˆé¢„æ³¨å†Œ
                                warn!("åå°ç›‘æ§ï¼šä»»åŠ¡ {} ä¸å­˜åœ¨ï¼Œå–æ¶ˆé¢„æ³¨å†Œ", id);
                                scheduler.cancel_pre_register();
                            }
                        }
                        None => {
                            // é˜Ÿåˆ—ä¸ºç©ºï¼Œå–æ¶ˆé¢„æ³¨å†Œ
                            scheduler.cancel_pre_register();
                            break;
                        }
                    }
                }
            }
        });
    }

    /// ğŸ”¥ ä»æ¢å¤ä¿¡æ¯åˆ›å»ºä¸Šä¼ ä»»åŠ¡
    ///
    /// ç”¨äºç¨‹åºå¯åŠ¨æ—¶æ¢å¤æœªå®Œæˆçš„ä¸Šä¼ ä»»åŠ¡
    /// æ¢å¤çš„ä»»åŠ¡åˆå§‹çŠ¶æ€ä¸º Pausedï¼Œéœ€è¦æ‰‹åŠ¨è°ƒç”¨ start_task å¯åŠ¨
    ///
    /// # Arguments
    /// * `recovery_info` - ä»æŒä¹…åŒ–æ–‡ä»¶æ¢å¤çš„ä»»åŠ¡ä¿¡æ¯
    ///
    /// # Returns
    /// æ¢å¤çš„ä»»åŠ¡ ID
    ///
    /// # æ³¨æ„
    /// - upload_id å¯èƒ½å·²è¿‡æœŸï¼Œå¯åŠ¨ä»»åŠ¡æ—¶ä¼šé‡æ–° precreate
    /// - å·²å®Œæˆçš„åˆ†ç‰‡ä¼šåœ¨åˆ†ç‰‡ç®¡ç†å™¨ä¸­æ ‡è®°ä¸ºå®Œæˆ
    pub async fn restore_task(&self, recovery_info: UploadRecoveryInfo) -> Result<String> {
        let task_id = recovery_info.task_id.clone();

        // æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å·²å­˜åœ¨
        if self.tasks.contains_key(&task_id) {
            anyhow::bail!("ä»»åŠ¡ {} å·²å­˜åœ¨ï¼Œæ— æ³•æ¢å¤", task_id);
        }

        // éªŒè¯æºæ–‡ä»¶å­˜åœ¨
        if !recovery_info.source_path.exists() {
            anyhow::bail!("æºæ–‡ä»¶ä¸å­˜åœ¨: {:?}", recovery_info.source_path);
        }

        // åˆ›å»ºæ¢å¤ä»»åŠ¡ï¼ˆä½¿ç”¨ Paused çŠ¶æ€ï¼‰
        let mut task = UploadTask::new(
            recovery_info.source_path.clone(),
            recovery_info.target_path.clone(),
            recovery_info.file_size,
        );

        // æ¢å¤ä»»åŠ¡ IDï¼ˆä¿æŒåŸæœ‰ IDï¼‰
        task.id = task_id.clone();

        // è®¾ç½®ä¸ºæš‚åœçŠ¶æ€ï¼ˆç­‰å¾…ç”¨æˆ·æ‰‹åŠ¨æ¢å¤ï¼‰
        task.status = UploadTaskStatus::Paused;

        // è®¾ç½®å·²ä¸Šä¼ å­—èŠ‚æ•°
        task.uploaded_size = recovery_info.uploaded_bytes();
        task.created_at = recovery_info.created_at;

        // è®¾ç½®åˆ†ç‰‡ä¿¡æ¯
        task.total_chunks = recovery_info.total_chunks;
        task.completed_chunks = recovery_info.completed_count();

        // åˆ›å»ºåˆ†ç‰‡ç®¡ç†å™¨å¹¶æ¢å¤å·²å®Œæˆåˆ†ç‰‡çŠ¶æ€
        let mut chunk_manager =
            UploadChunkManager::new(recovery_info.file_size, recovery_info.chunk_size);

        // æ ‡è®°å·²å®Œæˆçš„åˆ†ç‰‡
        for chunk_index in recovery_info.completed_chunks.iter() {
            let md5 = recovery_info.chunk_md5s.get(chunk_index).cloned().flatten();
            chunk_manager.mark_completed(chunk_index, md5);
        }

        // è®¡ç®—æœ€å¤§å¹¶å‘åˆ†ç‰‡æ•°
        let max_concurrent_chunks = calculate_upload_task_max_chunks(recovery_info.file_size);

        info!(
            "æ¢å¤ä¸Šä¼ ä»»åŠ¡: id={}, æ–‡ä»¶={:?}, å·²å®Œæˆ {}/{} åˆ†ç‰‡ ({:.1}%)",
            task_id,
            recovery_info.source_path,
            recovery_info.completed_count(),
            recovery_info.total_chunks,
            if recovery_info.total_chunks > 0 {
                (recovery_info.completed_count() as f64 / recovery_info.total_chunks as f64) * 100.0
            } else {
                0.0
            }
        );

        // ä¿å­˜ä»»åŠ¡ä¿¡æ¯
        let task_info = UploadTaskInfo {
            task: Arc::new(Mutex::new(task)),
            chunk_manager: Arc::new(Mutex::new(chunk_manager)),
            cancel_token: CancellationToken::new(),
            max_concurrent_chunks,
            active_chunk_count: Arc::new(AtomicUsize::new(0)),
            is_paused: Arc::new(AtomicBool::new(true)), // æ¢å¤çš„ä»»åŠ¡é»˜è®¤æš‚åœ
            uploaded_bytes: Arc::new(AtomicU64::new(recovery_info.uploaded_bytes())),
            last_speed_time: Arc::new(Mutex::new(std::time::Instant::now())),
            last_speed_bytes: Arc::new(AtomicU64::new(0)),
            // ğŸ”¥ ä¿å­˜æ¢å¤çš„ upload_idï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            restored_upload_id: recovery_info.upload_id.clone(),
        };

        self.tasks.insert(task_id.clone(), task_info);

        // ğŸ”¥ æ¢å¤æŒä¹…åŒ–çŠ¶æ€ï¼ˆé‡æ–°åŠ è½½åˆ°å†…å­˜ï¼‰
        if let Some(pm_arc) = self
            .persistence_manager
            .lock()
            .await
            .as_ref()
            .map(|pm| pm.clone())
        {
            if let Err(e) = pm_arc.lock().await.restore_task_state(
                &task_id,
                crate::persistence::TaskType::Upload,
                recovery_info.total_chunks,
            ) {
                warn!("æ¢å¤ä»»åŠ¡æŒä¹…åŒ–çŠ¶æ€å¤±è´¥: {}", e);
            }
        }

        Ok(task_id)
    }

    /// ğŸ”¥ æ‰¹é‡æ¢å¤ä¸Šä¼ ä»»åŠ¡
    ///
    /// ä»æ¢å¤ä¿¡æ¯åˆ—è¡¨æ‰¹é‡åˆ›å»ºä»»åŠ¡
    ///
    /// # Arguments
    /// * `recovery_infos` - æ¢å¤ä¿¡æ¯åˆ—è¡¨
    ///
    /// # Returns
    /// (æˆåŠŸæ•°, å¤±è´¥æ•°)
    pub async fn restore_tasks(&self, recovery_infos: Vec<UploadRecoveryInfo>) -> (usize, usize) {
        let mut success = 0;
        let mut failed = 0;

        for info in recovery_infos {
            match self.restore_task(info).await {
                Ok(_) => success += 1,
                Err(e) => {
                    warn!("æ¢å¤ä¸Šä¼ ä»»åŠ¡å¤±è´¥: {}", e);
                    failed += 1;
                }
            }
        }

        info!("ä¸Šä¼ ä»»åŠ¡æ‰¹é‡æ¢å¤å®Œæˆ: {} æˆåŠŸ, {} å¤±è´¥", success, failed);
        (success, failed)
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::auth::UserAuth;
    use crate::AppConfig;
    use std::fs;
    use std::io::Write;
    use tempfile::{NamedTempFile, TempDir};

    fn create_test_manager() -> UploadManager {
        let user_auth = UserAuth::new(123456789, "test_user".to_string(), "test_bduss".to_string());
        let client = NetdiskClient::new(user_auth.clone()).unwrap();
        let config = AppConfig::default();
        UploadManager::new_with_config(client, &user_auth, &config.upload)
    }

    #[tokio::test]
    async fn test_create_task() {
        let manager = create_test_manager();

        // åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        let mut temp_file = NamedTempFile::new().unwrap();
        let content = b"Test file content for upload";
        temp_file.write_all(content).unwrap();
        temp_file.flush().unwrap();

        let result = manager
            .create_task(
                temp_file.path().to_path_buf(),
                "/test/upload.txt".to_string(),
            )
            .await;

        assert!(result.is_ok());

        let task_id = result.unwrap();
        let task = manager.get_task(&task_id).await;

        assert!(task.is_some());
        let task = task.unwrap();
        assert_eq!(task.status, UploadTaskStatus::Pending);
        assert_eq!(task.total_size, content.len() as u64);
    }

    #[tokio::test]
    async fn test_get_all_tasks() {
        let manager = create_test_manager();

        // åˆ›å»ºå¤šä¸ªä¸´æ—¶æ–‡ä»¶å’Œä»»åŠ¡
        for i in 0..3 {
            let mut temp_file = NamedTempFile::new().unwrap();
            temp_file
                .write_all(format!("Content {}", i).as_bytes())
                .unwrap();
            temp_file.flush().unwrap();

            manager
                .create_task(
                    temp_file.path().to_path_buf(),
                    format!("/test/file{}.txt", i),
                )
                .await
                .unwrap();
        }

        let tasks = manager.get_all_tasks().await;
        assert_eq!(tasks.len(), 3);
    }

    #[tokio::test]
    async fn test_delete_task() {
        let manager = create_test_manager();

        let mut temp_file = NamedTempFile::new().unwrap();
        temp_file.write_all(b"Test content").unwrap();
        temp_file.flush().unwrap();

        let task_id = manager
            .create_task(
                temp_file.path().to_path_buf(),
                "/test/delete.txt".to_string(),
            )
            .await
            .unwrap();

        // ç¡®è®¤ä»»åŠ¡å­˜åœ¨
        assert!(manager.get_task(&task_id).await.is_some());

        // åˆ é™¤ä»»åŠ¡
        manager.delete_task(&task_id).await.unwrap();

        // ç¡®è®¤ä»»åŠ¡å·²åˆ é™¤
        assert!(manager.get_task(&task_id).await.is_none());
    }

    #[tokio::test]
    async fn test_create_folder_task() {
        let manager = create_test_manager();

        // åˆ›å»ºæµ‹è¯•æ–‡ä»¶å¤¹ç»“æ„
        let temp_dir = TempDir::new().unwrap();
        let root = temp_dir.path();

        // åˆ›å»ºæ–‡ä»¶
        fs::write(root.join("file1.txt"), "content1").unwrap();
        fs::write(root.join("file2.txt"), "content2").unwrap();

        // åˆ›å»ºå­ç›®å½•å’Œæ–‡ä»¶
        fs::create_dir(root.join("subdir")).unwrap();
        fs::write(root.join("subdir/file3.txt"), "content3").unwrap();

        // åˆ›å»ºæ–‡ä»¶å¤¹ä¸Šä¼ ä»»åŠ¡
        let result = manager
            .create_folder_task(root, "/test/folder".to_string(), None)
            .await;

        assert!(result.is_ok());

        let task_ids = result.unwrap();
        assert_eq!(task_ids.len(), 3, "åº”è¯¥åˆ›å»º3ä¸ªä¸Šä¼ ä»»åŠ¡");

        // éªŒè¯æ‰€æœ‰ä»»åŠ¡éƒ½å·²åˆ›å»º
        let all_tasks = manager.get_all_tasks().await;
        assert_eq!(all_tasks.len(), 3);

        // éªŒè¯ä»»åŠ¡çŠ¶æ€
        for task in all_tasks {
            assert_eq!(task.status, UploadTaskStatus::Pending);
            assert!(task.remote_path.starts_with("/test/folder/"));
        }
    }

    #[tokio::test]
    async fn test_create_folder_task_empty_folder() {
        let manager = create_test_manager();

        // åˆ›å»ºç©ºæ–‡ä»¶å¤¹
        let temp_dir = TempDir::new().unwrap();

        // å°è¯•åˆ›å»ºæ–‡ä»¶å¤¹ä¸Šä¼ ä»»åŠ¡
        let result = manager
            .create_folder_task(temp_dir.path(), "/test/empty".to_string(), None)
            .await;

        assert!(result.is_err());
        assert!(result
            .unwrap_err()
            .to_string()
            .contains("æ–‡ä»¶å¤¹ä¸ºç©ºæˆ–æ— å¯ä¸Šä¼ æ–‡ä»¶"));
    }

    #[tokio::test]
    async fn test_create_batch_tasks() {
        let manager = create_test_manager();

        // åˆ›å»ºå¤šä¸ªä¸´æ—¶æ–‡ä»¶
        let mut temp_files = Vec::new();
        for i in 0..3 {
            let mut temp_file = NamedTempFile::new().unwrap();
            temp_file
                .write_all(format!("Content {}", i).as_bytes())
                .unwrap();
            temp_file.flush().unwrap();
            temp_files.push(temp_file);
        }

        // å‡†å¤‡æ‰¹é‡ä»»åŠ¡
        let files: Vec<(PathBuf, String)> = temp_files
            .iter()
            .enumerate()
            .map(|(i, f)| (f.path().to_path_buf(), format!("/test/file{}.txt", i)))
            .collect();

        // æ‰¹é‡åˆ›å»ºä»»åŠ¡
        let result = manager.create_batch_tasks(files).await;

        assert!(result.is_ok());

        let task_ids = result.unwrap();
        assert_eq!(task_ids.len(), 3);

        // éªŒè¯æ‰€æœ‰ä»»åŠ¡
        let all_tasks = manager.get_all_tasks().await;
        assert_eq!(all_tasks.len(), 3);
    }
}
